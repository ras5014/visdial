{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.10.2'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the impports\n",
    "import copy\n",
    "import json\n",
    "import multiprocessing as mp\n",
    "from typing import Any, Dict, List, Optional, Set, Union\n",
    "\n",
    "import h5py\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tqdm import tqdm # Used for displaying progress bars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Feature Reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageFeaturesHdfReader(object):\n",
    "    def __init__(self, features_hdfpath: str, in_memory: bool = False):\n",
    "        self.features_hdfpath = features_hdfpath\n",
    "        self._in_memory = in_memory\n",
    "\n",
    "        with h5py.File(self.features_hdfpath, \"r\") as features_hdf:\n",
    "            self._split = features_hdf.attrs[\"split\"]\n",
    "            self._image_id_list = list(features_hdf[\"image_id\"])\n",
    "            self.features = [None] * len(self._image_id_list)\n",
    "    def __len__(self):\n",
    "        return len(self._image_id_list)\n",
    "    def __getitem__(self, image_id: int):\n",
    "        index = self._image_id_list.index(image_id)\n",
    "        if self._in_memory:\n",
    "            # Load features during the first epoch, all not loaded together as it\n",
    "            # has a slow start.\n",
    "            if self.features[index] is not None:\n",
    "                image_id_features = self.features[index]\n",
    "            else:\n",
    "                with h5py.File(self.features_hdfpath, \"r\") as features_hdf:\n",
    "                    image_id_features = features_hdf[\"features\"][index]\n",
    "                    self.features[index] = image_id_features\n",
    "        else:\n",
    "            # Read chunk from file every time if not loaded in memory.\n",
    "            with h5py.File(self.features_hdfpath, \"r\") as features_hdf:\n",
    "                image_id_features = features_hdf[\"features\"][index]\n",
    "\n",
    "        return image_id_features\n",
    "    \n",
    "    def keys(self) -> List[int]:\n",
    "        return self._image_id_list\n",
    "    \n",
    "    def split(self):\n",
    "        return self._split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dialogs Reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import json\n",
    "import multiprocessing as mp\n",
    "from typing import Any, Dict, List, Optional, Set, Union\n",
    "\n",
    "import h5py\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DialogsReader(object):\n",
    "    \"\"\"\n",
    "    A simple reader for VisDial v1.0 dialog data. The json file must have the\n",
    "    same structure as mentioned on ``https://visualdialog.org/data``.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dialogs_jsonpath : str\n",
    "        Path to json file containing VisDial v1.0 train, val or test data.\n",
    "    num_examples: int, optional (default = None)\n",
    "        Process first ``num_examples`` from the split. Useful to speed up while\n",
    "        debugging.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        dialogs_jsonpath: str,\n",
    "        num_examples: Optional[int] = None,\n",
    "        num_workers: int = 1,\n",
    "    ):\n",
    "        with open(dialogs_jsonpath, \"r\") as visdial_file:\n",
    "            visdial_data = json.load(visdial_file)\n",
    "            self._split = visdial_data[\"split\"]\n",
    "\n",
    "            # Maintain questions and answers as a dict instead of list because\n",
    "            # they are referenced by index in dialogs. We drop elements from\n",
    "            # these in \"overfit\" mode to save time (tokenization is slow).\n",
    "            self.questions = {\n",
    "                i: question for i, question in\n",
    "                enumerate(visdial_data[\"data\"][\"questions\"])\n",
    "            }\n",
    "            self.answers = {\n",
    "                i: answer for i, answer in\n",
    "                enumerate(visdial_data[\"data\"][\"answers\"])\n",
    "            }\n",
    "\n",
    "            # Add empty question, answer - useful for padding dialog rounds\n",
    "            # for test split.\n",
    "            self.questions[-1] = \"\"\n",
    "            self.answers[-1] = \"\"\n",
    "\n",
    "            # ``image_id``` serves as key for all three dicts here.\n",
    "            self.captions: Dict[int, Any] = {}\n",
    "            self.dialogs: Dict[int, Any] = {}\n",
    "            self.num_rounds: Dict[int, Any] = {}\n",
    "\n",
    "            all_dialogs = visdial_data[\"data\"][\"dialogs\"]\n",
    "\n",
    "            # Retain only first ``num_examples`` dialogs if specified.\n",
    "            if num_examples is not None:\n",
    "                all_dialogs = all_dialogs[:num_examples]\n",
    "\n",
    "            for _dialog in all_dialogs:\n",
    "\n",
    "                self.captions[_dialog[\"image_id\"]] = _dialog[\"caption\"]\n",
    "\n",
    "                # Record original length of dialog, before padding.\n",
    "                # 10 for train and val splits, 10 or less for test split.\n",
    "                self.num_rounds[_dialog[\"image_id\"]] = len(_dialog[\"dialog\"])\n",
    "\n",
    "                # Pad dialog at the end with empty question and answer pairs\n",
    "                # (for test split).\n",
    "                while len(_dialog[\"dialog\"]) < 10:\n",
    "                    _dialog[\"dialog\"].append({\"question\": -1, \"answer\": -1})\n",
    "\n",
    "                # Add empty answer (and answer options) if not provided\n",
    "                # (for test split). We use \"-1\" as a key for empty questions\n",
    "                # and answers.\n",
    "                for i in range(len(_dialog[\"dialog\"])):\n",
    "                    if \"answer\" not in _dialog[\"dialog\"][i]:\n",
    "                        _dialog[\"dialog\"][i][\"answer\"] = -1\n",
    "                    if \"answer_options\" not in _dialog[\"dialog\"][i]:\n",
    "                        _dialog[\"dialog\"][i][\"answer_options\"] = [-1] * 100\n",
    "\n",
    "                self.dialogs[_dialog[\"image_id\"]] = _dialog[\"dialog\"]\n",
    "\n",
    "            # If ``num_examples`` is specified, collect questions and answers\n",
    "            # included in those examples, and drop the rest to save time while\n",
    "            # tokenizing. Collecting these should be fast because num_examples\n",
    "            # during debugging are generally small.\n",
    "            if num_examples is not None:\n",
    "                questions_included: Set[int] = set()\n",
    "                answers_included: Set[int] = set()\n",
    "\n",
    "                for _dialog in self.dialogs.values():\n",
    "                    for _dialog_round in _dialog:\n",
    "                        questions_included.add(_dialog_round[\"question\"])\n",
    "                        answers_included.add(_dialog_round[\"answer\"])\n",
    "                        for _answer_option in _dialog_round[\"answer_options\"]:\n",
    "                            answers_included.add(_answer_option)\n",
    "\n",
    "                self.questions = {\n",
    "                    i: self.questions[i] for i in questions_included\n",
    "                }\n",
    "                self.answers = {\n",
    "                    i: self.answers[i] for i in answers_included\n",
    "                }\n",
    "\n",
    "            self._multiprocess_tokenize(num_workers)\n",
    "\n",
    "    def _multiprocess_tokenize(self, num_workers: int):\n",
    "        \"\"\"\n",
    "        Tokenize captions, questions and answers in parallel processes. This\n",
    "        method uses multiprocessing module internally.\n",
    "\n",
    "        Since questions, answers and captions are dicts - and multiprocessing\n",
    "        map utilities operate on lists, we convert these to lists first and\n",
    "        then back to dicts.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        num_workers: int\n",
    "            Number of workers (processes) to run in parallel.\n",
    "        \"\"\"\n",
    "\n",
    "        # While displaying progress bar through tqdm, specify total number of\n",
    "        # sequences to tokenize, because tqdm won't know in case of pool.imap\n",
    "        with mp.Pool(num_workers) as pool:\n",
    "            print(f\"[{self._split}] Tokenizing questions...\")\n",
    "            _question_tuples = self.questions.items()\n",
    "            _question_indices = [t[0] for t in _question_tuples]\n",
    "            _questions = list(\n",
    "                tqdm(\n",
    "                    pool.imap(word_tokenize, [t[1] for t in _question_tuples]),\n",
    "                    total=len(self.questions)\n",
    "                )\n",
    "            )\n",
    "            self.questions = {\n",
    "                i: question + [\"?\"] for i, question in\n",
    "                zip(_question_indices, _questions)\n",
    "            }\n",
    "            # Delete variables to free memory.\n",
    "            del _question_tuples, _question_indices, _questions\n",
    "\n",
    "            print(f\"[{self._split}] Tokenizing answers...\")\n",
    "            _answer_tuples = self.answers.items()\n",
    "            _answer_indices = [t[0] for t in _answer_tuples]\n",
    "            _answers = list(\n",
    "                tqdm(\n",
    "                    pool.imap(word_tokenize, [t[1] for t in _answer_tuples]),\n",
    "                    total=len(self.answers)\n",
    "                )\n",
    "            )\n",
    "            self.answers = {\n",
    "                i: answer + [\"?\"] for i, answer in\n",
    "                zip(_answer_indices, _answers)\n",
    "            }\n",
    "            # Delete variables to free memory.\n",
    "            del _answer_tuples, _answer_indices, _answers\n",
    "\n",
    "            print(f\"[{self._split}] Tokenizing captions...\")\n",
    "            # Convert dict to separate lists of image_ids and captions.\n",
    "            _caption_tuples = self.captions.items()\n",
    "            _image_ids = [t[0] for t in _caption_tuples]\n",
    "            _captions = list(\n",
    "                tqdm(\n",
    "                    pool.imap(word_tokenize, [t[1] for t in _caption_tuples]),\n",
    "                    total=(len(_caption_tuples))\n",
    "                )\n",
    "            )\n",
    "            # Convert tokenized captions back to a dict.\n",
    "            self.captions = {i: c for i, c in zip(_image_ids, _captions)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dialogs)\n",
    "\n",
    "    def __getitem__(self, image_id: int) -> Dict[str, Union[int, str, List]]:\n",
    "        caption_for_image = self.captions[image_id]\n",
    "        dialog = copy.copy(self.dialogs[image_id])\n",
    "        num_rounds = self.num_rounds[image_id]\n",
    "\n",
    "        # Replace question and answer indices with actual word tokens.\n",
    "        for i in range(len(dialog)):\n",
    "            dialog[i][\"question\"] = self.questions[\n",
    "                dialog[i][\"question\"]\n",
    "            ]\n",
    "            dialog[i][\"answer\"] = self.answers[\n",
    "                dialog[i][\"answer\"]\n",
    "            ]\n",
    "            for j, answer_option in enumerate(\n",
    "                dialog[i][\"answer_options\"]\n",
    "            ):\n",
    "                dialog[i][\"answer_options\"][j] = self.answers[\n",
    "                    answer_option\n",
    "                ]\n",
    "\n",
    "        return {\n",
    "            \"image_id\": image_id,\n",
    "            \"caption\": caption_for_image,\n",
    "            \"dialog\": dialog,\n",
    "            \"num_rounds\": num_rounds,\n",
    "        }\n",
    "\n",
    "    def keys(self) -> List[int]:\n",
    "        return list(self.dialogs.keys())\n",
    "\n",
    "    @property\n",
    "    def split(self):\n",
    "        return self._split         \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DenseAnnotationsReader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseAnnotationsReader(object):\n",
    "    \"\"\"\n",
    "    A reader for dense annotations for val split. The json file must have the\n",
    "    same structure as mentioned on ``https://visualdialog.org/data``.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dense_annotations_jsonpath : str\n",
    "        Path to a json file containing VisDial v1.0\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dense_annotations_jsonpath: str):\n",
    "        with open(dense_annotations_jsonpath, \"r\") as visdial_file:\n",
    "            self._visdial_data = json.load(visdial_file)\n",
    "            self._image_ids = [\n",
    "                entry[\"image_id\"] for entry in self._visdial_data\n",
    "            ]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._image_ids)\n",
    "\n",
    "    def __getitem__(self, image_id: int) -> Dict[str, Union[int, List]]:\n",
    "        index = self._image_ids.index(image_id)\n",
    "        # keys: {\"image_id\", \"round_id\", \"gt_relevance\"}\n",
    "        return self._visdial_data[index]\n",
    "\n",
    "    @property\n",
    "    def split(self):\n",
    "        # always\n",
    "        return \"val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
